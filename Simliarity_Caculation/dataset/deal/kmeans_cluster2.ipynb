{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\think\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading doc2vec model...\n",
      "training kmeans model...\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    " \n",
    "import sys\n",
    "import gensim\n",
    "import numpy as np\n",
    " \n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "TaggededDocument = gensim.models.doc2vec.TaggedDocument\n",
    "def get_datasest():\n",
    "    with open(\"D:\\python\\src\\TCM clustering\\cut.txt\", 'r',encoding=\"utf8\") as f:\n",
    "        docs = f.readlines()\n",
    "    train_input = []\n",
    "    for patent_id, patent_abstract_text in enumerate(docs):\n",
    "        word_list = patent_abstract_text.split(' ')\n",
    "        l = len(word_list)\n",
    "        document = TaggededDocument(word_list, tags=[patent_id])\n",
    "        train_input.append(document)\n",
    "    return train_input\n",
    " \n",
    "def train(train_input):\n",
    "    model_doc2vec = Doc2Vec(train_input,min_count=1, window = 3, vector_size = 200, \n",
    "                       sample=1e-3, negative=5, workers=5)\n",
    "    model_doc2vec.train(train_input, total_examples=model_doc2vec.corpus_count, epochs=5)\n",
    "    model_doc2vec.save('D:\\python\\src\\TCM clustering\\model_doc2vec')\n",
    "    return model_doc2vec\n",
    " \n",
    "def cluster(train_input):\n",
    "    infered_vectors_list = []\n",
    "    print(\"loading doc2vec model...\")\n",
    "    model_doc2vec= Doc2Vec.load(\"D:\\python\\src\\TCM clustering\\model_doc2vec\")\n",
    "    i = 0\n",
    "    for text, label in train_input:\n",
    "        vector = model_doc2vec.infer_vector(text)\n",
    "        infered_vectors_list.append(vector)\n",
    "        i += 1\n",
    "    print(\"training kmeans model...\")\n",
    "    kmean_model = KMeans(n_clusters=15)\n",
    "    kmean_model.fit(infered_vectors_list)\n",
    "    labels= kmean_model.predict(infered_vectors_list[0:7000])\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(15): #for each cluster\n",
    "        f=open(\"D:\\python\\src\\TCM clustering\\classify_\"+str(i)+\".txt\", 'w',\n",
    "               encoding=\"utf8\") \n",
    "        cluster_words=[]#word sequence of each cluster\n",
    "        cluster_str=''# word sequence string of each cluster\n",
    "        for j in range(0,7000):\n",
    "            if(labels[j]==i): \n",
    "                text = train_input[j][0]  \n",
    "                cluster_words=cluster_words+text\n",
    "        cluster_str=' '.join(map(str,cluster_words))\n",
    "        f.write(cluster_str)\n",
    "        f.close()\n",
    "    \n",
    "        \n",
    "\n",
    "    with open(\"D:\\python\\src\\TCM clustering\\classify.txt\", 'w',encoding=\"utf8\") as wf:\n",
    "        for i in range(7000):\n",
    "            string = \"\"\n",
    "            text = train_input[i][0]\n",
    "            for word in text:\n",
    "                string = string + word+' '\n",
    "            string = string + '\\t'\n",
    "            string = string + str(labels[i])\n",
    "            string = string + '\\n'\n",
    "            wf.write(string)\n",
    "        return labels\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "#     return cluster_centers\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    train_input = get_datasest()\n",
    "    model_doc2vec = train(train_input)\n",
    "    cluster_centers = cluster(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}